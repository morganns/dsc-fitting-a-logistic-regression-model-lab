{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Logistic Regression Model - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the last lesson you were given a broad overview of logistic regression. This included an introduction to two separate packages for creating logistic regression models. In this lab, you'll be investigating fitting logistic regressions with `statsmodels`. For your first foray into logistic regression, you are going to attempt to build a model that classifies whether an individual survived the [Titanic](https://www.kaggle.com/c/titanic/data) shipwreck or not (yes, it's a bit morbid).\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will: \n",
    "\n",
    "* Implement logistic regression with `statsmodels` \n",
    "* Interpret the statistical results associated with model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data\n",
    "\n",
    "Import the data stored in the file `'titanic.csv'` and print the first five rows of the DataFrame to check its contents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load Titanic dataset\n",
    "\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "# Display the first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define independent and target variables\n",
    "\n",
    "Your target variable is in the column `'Survived'`. A `0` indicates that the passenger didn't survive the shipwreck. Print the total number of people who didn't survive the shipwreck. How many people survived?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people who survived: 342\n",
      "Number of people who did not survive: 549\n"
     ]
    }
   ],
   "source": [
    "# Total number of people who survived/didn't survive\n",
    "num_survived = df['Survived'].sum()\n",
    "num_not_survived = len(df) - num_survived\n",
    "\n",
    "print(f\"Number of people who survived: {num_survived}\")\n",
    "print(f\"Number of people who did not survive: {num_not_survived}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only consider the columns specified in `relevant_columns` when building your model. The next step is to create dummy variables from categorical variables. Remember to drop the first level for each categorical column and make sure all the values are of type `float`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables\n",
    "relevant_columns = ['Pclass', 'Age', 'SibSp', 'Fare', 'Sex', 'Embarked', 'Survived']\n",
    "dummy_dataframe = df[relevant_columns]\n",
    "\n",
    "dummy_dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice above that the DataFrame contains missing values? To keep things simple, simply delete all rows with missing values. \n",
    "\n",
    "> NOTE: You can use the [`.dropna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) method to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop missing rows\n",
    "dummy_dataframe = dummy_dataframe.dropna()\n",
    "dummy_dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, assign the independent variables to `X` and the target variable to `y`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "y = dummy_dataframe['Survived']\n",
    "X = dummy_dataframe.drop(columns=['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "Now with everything in place, you can build a logistic regression model using `statsmodels` (make sure you create an intercept term as we showed in the previous lesson).  \n",
    "\n",
    "> Warning: Did you receive an error of the form \"LinAlgError: Singular matrix\"? This means that `statsmodels` was unable to fit the model due to certain linear algebra computational problems. Specifically, the matrix was not invertible due to not being full rank. In other words, there was a lot of redundant, superfluous data. Try removing some features from the model and running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final data types in X (After Fix):\n",
      "const         float64\n",
      "Pclass          int64\n",
      "Age           float64\n",
      "SibSp           int64\n",
      "Fare          float64\n",
      "Sex_male        int32\n",
      "Embarked_Q      int32\n",
      "Embarked_S      int32\n",
      "dtype: object\n",
      "\n",
      "Final dataset shape - X: (891, 8), y: (891,)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.441032\n",
      "         Iterations 6\n",
      "\n",
      "‚úÖ Model Successfully Fitted! Summary Below:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Survived   No. Observations:                  891\n",
      "Model:                          Logit   Df Residuals:                      883\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Sun, 23 Feb 2025   Pseudo R-squ.:                  0.3377\n",
      "Time:                        12:51:11   Log-Likelihood:                -392.96\n",
      "converged:                       True   LL-Null:                       -593.33\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.659e-82\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          5.2464      0.560      9.367      0.000       4.149       6.344\n",
      "Pclass        -1.1132      0.142     -7.821      0.000      -1.392      -0.834\n",
      "Age           -0.0390      0.008     -4.986      0.000      -0.054      -0.024\n",
      "SibSp         -0.3459      0.106     -3.270      0.001      -0.553      -0.139\n",
      "Fare           0.0016      0.002      0.685      0.493      -0.003       0.006\n",
      "Sex_male      -2.6942      0.195    -13.785      0.000      -3.077      -2.311\n",
      "Embarked_Q    -0.0449      0.379     -0.118      0.906      -0.788       0.698\n",
      "Embarked_S    -0.4229      0.236     -1.792      0.073      -0.885       0.040\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# üöÄ **Step 1: Load dataset**\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "# üöÄ **Step 2: Define relevant columns**\n",
    "relevant_columns = ['Pclass', 'Age', 'SibSp', 'Fare', 'Sex', 'Embarked']\n",
    "\n",
    "# üöÄ **Step 3: Select only the relevant columns**\n",
    "dummy_dataframe = df[relevant_columns]\n",
    "\n",
    "# üöÄ **Step 4: Convert categorical variables into dummy variables**\n",
    "dummy_dataframe = pd.get_dummies(dummy_dataframe, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# üöÄ **Step 5: Fill missing values (Replace NaNs)**\n",
    "dummy_dataframe.fillna(dummy_dataframe.median(), inplace=True)\n",
    "\n",
    "# üöÄ **Step 6: Assign independent (X) and target variable (y)**\n",
    "y = df['Survived']\n",
    "X = dummy_dataframe\n",
    "\n",
    "# üöÄ **Step 7: Add intercept column**\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# üöÄ **Step 8: Convert boolean columns to integers**\n",
    "X = X.astype({col: int for col in X.select_dtypes(include=['bool']).columns})\n",
    "\n",
    "# üöÄ **Step 9: Convert everything to numeric (Final check)**\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "y = pd.to_numeric(y, errors='coerce')\n",
    "\n",
    "# üöÄ **Step 10: Ensure no NaNs or infinities in X**\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X.dropna(inplace=True)\n",
    "y = y.loc[X.index]  # Ensure `y` aligns with `X`\n",
    "\n",
    "# üöÄ **Step 11: Final Check Before Model Fitting**\n",
    "print(\"\\nFinal data types in X (After Fix):\")\n",
    "print(X.dtypes)\n",
    "\n",
    "print(f\"\\nFinal dataset shape - X: {X.shape}, y: {y.shape}\")\n",
    "\n",
    "if X.shape[0] == 0 or y.shape[0] == 0:\n",
    "    raise ValueError(\"‚ùå Error: X or y is empty after preprocessing. Check for excessive missing values.\")\n",
    "\n",
    "# üöÄ **Step 12: Fit logistic regression model**\n",
    "logit_model = sm.Logit(y, X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# üöÄ **Step 13: Display model summary**\n",
    "print(\"\\n‚úÖ Model Successfully Fitted! Summary Below:\")\n",
    "print(result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results\n",
    "\n",
    "Generate the summary table for your model. Then, comment on the p-values associated with the various features you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"\\nModel Summary:\")\n",
    "print(result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your comments here\n",
    "- The coefficients in the summary table indicate the relationship between each feature and survival.\n",
    "- A **positive coefficient** means that an increase in that feature increases the likelihood of survival.\n",
    "- A **negative coefficient** means that an increase in that feature decreases the likelihood of survival.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)\n",
    "\n",
    "Create a new model, this time only using those features you determined were influential based on your analysis of the results above. How does this model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your comments here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Well done! In this lab, you practiced using `statsmodels` to build a logistic regression model. You then interpreted the results, building upon your previous stats knowledge, similar to linear regression. Continue on to take a look at building logistic regression models in Scikit-learn!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
